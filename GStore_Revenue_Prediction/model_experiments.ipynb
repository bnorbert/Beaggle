{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\nimport gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\ncolor = sns.color_palette()\n\n# Import plotly\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\nfrom sklearn import preprocessing",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76c9c13dbea147ea3b8f49195af622ed7e2f4878"
      },
      "cell_type": "code",
      "source": "gc.enable()\n\nfeatures = ['channelGrouping', 'date', 'fullVisitorId', 'visitId',\\\n       'visitNumber', 'visitStartTime', 'device.browser',\\\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\\\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\\\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\\\n       'geoNetwork.subContinent', 'totals.bounces', 'totals.hits',\\\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue',\\\n       'trafficSource.adContent', 'trafficSource.campaign',\\\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\\\n       'trafficSource.medium', 'trafficSource.referralPath',\\\n       'trafficSource.source', 'customDimensions']\n\ndef load_df(csv_path):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    ans = pd.DataFrame()\n    dfs = pd.read_csv(csv_path, sep=',',\n            converters={column: json.loads for column in JSON_COLUMNS}, \n            dtype={'fullVisitorId': 'str'}, # Important!!\n            chunksize=100000)\n    for df in dfs:\n        df.reset_index(drop=True, inplace=True)\n        for column in JSON_COLUMNS:\n            column_as_df = json_normalize(df[column])\n            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n\n        #print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n        use_df = df[features]\n        del df\n        gc.collect()\n        ans = pd.concat([ans, use_df], axis=0).reset_index(drop=True)\n        #print(ans.shape)\n    return ans\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93afb10a941bfa80038f0dacb7b24c5487322c2c"
      },
      "cell_type": "code",
      "source": "%%time\ntrain_df = load_df('../input/train_v2.csv')\ntest_df = load_df('../input/test_v2.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de2b6358347cc4adfa272f7c073f8da8abf162c6"
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36936f96c33078c5b52b24e7edc0b0d6cf27aa5d"
      },
      "cell_type": "code",
      "source": "print(\"Number of unique full VisitorIds: %d\" % train_df.fullVisitorId.unique().shape[0])\nprint(\"Number of entries in training data: %d\" % train_df.shape[0])\nprint(\"Ratio of unique visitorids per entries in train: %s\" % str(train_df.fullVisitorId.unique().shape[0] * 1.0 / train_df.shape[0]))\nprint(\"Number of unique full VisitorIds: %d\" % test_df.fullVisitorId.unique().shape[0])\nprint(\"Number of entries in test data: %d\" % test_df.shape[0])\nprint(\"Ratio of unique visitorids per entries in test: %s\" % str(test_df.fullVisitorId.unique().shape[0] * 1.0 / test_df.shape[0]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "454ed4a8ac8eeb58c2816843bda520b67f410267"
      },
      "cell_type": "code",
      "source": "cat_cols = [\"channelGrouping\", \"device.browser\", \n            \"device.deviceCategory\", \"device.operatingSystem\", \n            \"geoNetwork.city\", \"geoNetwork.continent\", \n            \"geoNetwork.country\", \"geoNetwork.metro\",\n            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \"trafficSource.campaign\", \n            \"trafficSource.source\",\n            \"trafficSource.isTrueDirect\"]\nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits'] \n\ncols_to_drop = [ \"device.isMobile\", \"customDimensions\", \"visitId\", \"trafficSource.referralPath\", \"trafficSource.medium\", \"trafficSource.keyword\"]\n\nfor c in cat_cols:\n    if c not in train_df.columns:\n        print(c)\nprint(\"-\"* 30)        \nfor c in train_df.columns:\n    if (c not in cat_cols) and (c not in num_cols):\n        print(c)\nprint(\"-\" * 30)\nfor c in test_df.columns:\n    if ( c not in cat_cols) and (c not in num_cols):\n        print(c)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8e34cf892ae373ba540d54af42d311e66972ee9"
      },
      "cell_type": "code",
      "source": "train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype(float)\ntest_df[\"totals.transactionRevenue\"] = test_df[\"totals.transactionRevenue\"].astype(float)\ntrain_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntest_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)\ntest_id = test_df[\"fullVisitorId\"].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05fd9c3db0620631f8075334540e6c423bca03d3"
      },
      "cell_type": "code",
      "source": "train_df['date'] = pd.to_datetime(train_df['date'], format='%Y%m%d')\ntest_df['date'] = pd.to_datetime(test_df['date'], format='%Y%m%d')\ntrain_df.drop(cols_to_drop, axis=1, inplace=True)\ntest_df.drop(cols_to_drop, axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d94b593d9f782690847887507eca98a20b1f2960",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "%%time\nfor col in cat_cols:\n    print(col)\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de319ea5c9fcdaf31889bcbc06e422629fc3be92"
      },
      "cell_type": "code",
      "source": "for col in num_cols:\n    train_df[col] = train_df[col].astype(float)\n    test_df[col] = test_df[col].astype(float)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "633e7bae2f288e39fc7c5fb9f6d73e6d1991d4d2"
      },
      "cell_type": "code",
      "source": "print(train_df.shape)\ntrain_df.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f65e24dcc59e0f1d79afa1501bf8c5a581b2f174"
      },
      "cell_type": "code",
      "source": "# Split the train dataset into development and valid based on time \ndev_df = train_df[train_df['date']<=datetime(2017,6,30)]\nval_df = train_df[train_df['date']>datetime(2017,6,30)]\nprint(dev_df.shape)\nprint(val_df.shape)\ndev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\nval_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)\n\ndev_X = dev_df[cat_cols + num_cols] \nval_X = val_df[cat_cols + num_cols] \ntest_X = test_df[cat_cols + num_cols] ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8be310f947d86119b99d65badc2f3b43f411ddd"
      },
      "cell_type": "code",
      "source": "# custom function to run light gbm model\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\", \n        \"num_leaves\" : 30,\n        \"min_child_samples\" : 100,\n        \"learning_rate\" : 0.1,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, pred_val_y\n\n# Training the model #\npred_test, model, pred_val = run_lgb(dev_X, dev_y, val_X, val_y, test_X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db91fc77ea1fdeab141bb549a73cac4824b19a22"
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\npred_val[pred_val<0] = 0\nval_pred_df = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\nval_pred_df[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\nval_pred_df[\"PredictedRevenue\"] = np.expm1(pred_val)\n#print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))\nval_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\nprint(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e4eacc727bbe9575bf53734d65b34cbbab40957"
      },
      "cell_type": "code",
      "source": "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\npred_test[pred_test<0] = 0\nsub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\nsub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\nsub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\nsub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\nsub_df.to_csv(\"baseline_lgb.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c59571ec5476d6ab7ba46084dddb7ca7439b9725"
      },
      "cell_type": "code",
      "source": "sub_df.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8134e4e115076d1b2a0499ca8252ccaee5751b8e"
      },
      "cell_type": "code",
      "source": "fig, ax = plt.subplots(figsize=(12,18))\nlgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ee8f16ca9526a338142db5ed2d7d8656377122d"
      },
      "cell_type": "code",
      "source": "y_train = train_df[\"totals.transactionRevenue\"].values\ny_val = test_df[\"totals.transactionRevenue\"].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf0d9c8c4acc2c051061f5dd2a32dc538bd37d90"
      },
      "cell_type": "code",
      "source": "df_train_x = train_df.drop([\"totals.transactionRevenue\", \"fullVisitorId\", \"date\"], axis = 1)\ndf_test_x = test_df.drop([\"totals.transactionRevenue\", \"fullVisitorId\", \"date\"], axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9326e91f7176a94ac6c86f027d364f0f26f311ed"
      },
      "cell_type": "code",
      "source": "df_train_x.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f07d3d3a4ec86514bfe9b21b46bfa26ab12d609"
      },
      "cell_type": "code",
      "source": "#from keras.models import Sequential\n#from keras.layers import Dense\n#from keras.layers import LSTM, Bidirectional, Dropout\n#from keras.callbacks import ReduceLROnPlateau\n\n#X_train = df_train_x.values\n#X_val = df_test_x.values\n#y_train = y_train\n#y_val = y_val\n#X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n#X_val = X_val.reshape(X_val.shape[0],1,X_val.shape[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28536a05b8318a86315a1159dc54a4dc32229853"
      },
      "cell_type": "code",
      "source": "#from keras.layers import Input\n#from keras.models import Model\n\n#inputs = Input(shape=(1,21))\n#x = Bidirectional(LSTM(200,recurrent_dropout=0.2, kernel_initializer='lecun_normal', return_sequences=True))(inputs)\n#x = Bidirectional(LSTM(120,recurrent_dropout=0.2, kernel_initializer='lecun_normal'))(x)\n#x = Dense(50, activation='sigmoid')(inputs)\n#x = Dropout(0.1)(x)\n#x = Dense(20,activation='elu')(x)\n#output = Dense(1,activation='linear')(x)\n\n#model2 = Model(inputs=inputs, outputs=output)\n#model2.compile(loss='mse', optimizer='adam')\n#model2.fit(X_train, y_train, epochs=4, batch_size=64, validation_data=(X_val, y_val), verbose=1, shuffle=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63069357d16e466bffdc07a2c64837ca7c676dce"
      },
      "cell_type": "code",
      "source": "import xgboost as xgb\ndef run_xgb(X_train, y_train, X_val, y_val, X_test):\n    params = {'objective': 'reg:linear',\n              'eval_metric': 'rmse',\n              'eta': 0.001,\n              'max_depth': 10,\n              'subsample': 0.6,\n              'colsample_bytree': 0.6,\n              'alpha':0.001,\n              'random_state': 42,\n              'silent': True}\n\n    xgb_train_data = xgb.DMatrix(X_train, y_train)\n    xgb_val_data = xgb.DMatrix(X_val, y_val)\n    xgb_submit_data = xgb.DMatrix(X_test)\n\n    model = xgb.train(params, xgb_train_data, \n                      num_boost_round=1000, \n                      evals= [(xgb_train_data, 'train'), (xgb_val_data, 'valid')],\n                      early_stopping_rounds=100, \n                      verbose_eval=500\n                     )\n\n    y_pred_train = model.predict(xgb_train_data, ntree_limit=model.best_ntree_limit)\n    y_pred_val = model.predict(xgb_val_data, ntree_limit=model.best_ntree_limit)\n    y_pred_submit = model.predict(xgb_submit_data, ntree_limit=model.best_ntree_limit)\n\n    return y_pred_submit, model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9fa5b3447856a7c69329e4b7a1c0fb7543eef06"
      },
      "cell_type": "code",
      "source": "%%time\nxgb_preds, xgb_model = run_xgb(dev_X, dev_y, val_X, val_y, test_X)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c4022e365ef56251576245e4e252d8d5fd80534"
      },
      "cell_type": "code",
      "source": "sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\npred_test[pred_test<0] = 0\nsub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test * 0.6 + xgb_preds * 0.4)\nsub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\nsub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\nsub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])\nsub_df.to_csv(\"prediction_ensemble_xgb_lgb.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87878a6e5df158d30db34f9fc9caf7c787036c49"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}